{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bbf783e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from rapidfuzz import process, fuzz\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b5e8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\S rajiv\n",
      "[nltk_data]     gandhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\S rajiv\n",
      "[nltk_data]     gandhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b69492fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "reviews_df = pd.read_excel(\"mid_size_sedan.xlsx\")\n",
    "features_df = pd.read_excel(\"predefined_features.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e64d253",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = features_df.iloc[:, 0].dropna().str.lower().str.strip().unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfca8736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text cleaning function\n",
    "def clean_text(text):\n",
    "    if pd.isnull(text):\n",
    "        return \"\"\n",
    "    text = text.lower()  # lowercase\n",
    "    text = re.sub(r'\\d+', '', text)  # remove digits\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))  # remove punctuation\n",
    "    tokens = word_tokenize(text)  # tokenize\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    tokens = [word for word in tokens if word not in stop_words]  # remove stopwords\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# cleaning\n",
    "reviews_df[\"Cleaned_Review\"] = reviews_df[\"Review\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04a6be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Review  \\\n",
      "0  Great Family Car\\nGood car for day-to-day usag...   \n",
      "1  LKAS & RDMS\\nI have purchased honda amaze top ...   \n",
      "2  Sure Fo Good Deal.\\nVery good preference car i...   \n",
      "3  Best Quality Driving Experience Top Level Comf...   \n",
      "4  It Is A Perfect Family Car\\nIt is a perfect fa...   \n",
      "\n",
      "                                      Cleaned_Review   Car Company  \n",
      "0  great family car good car daytoday usage famil...  City   Honda  \n",
      "1  lkas rdms purchased honda amaze top mode autom...  City   Honda  \n",
      "2  sure fo good deal good preference car give val...  City   Honda  \n",
      "3  best quality driving experience top level comf...  City   Honda  \n",
      "4  perfect family car perfect family car spacious...  City   Honda  \n",
      "\n",
      "Total predefined features loaded: 204\n"
     ]
    }
   ],
   "source": [
    "# cleaned data\n",
    "print(reviews_df[[\"Review\", \"Cleaned_Review\", \"Car\", \"Company\"]].head())\n",
    "print(f\"\\nTotal predefined features loaded: {len(features_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb95f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exact and Fuzzy Matching Function\n",
    "def match_features_in_review(review, threshold=90):\n",
    "    matched_features = set()\n",
    "\n",
    "    # Exact matches\n",
    "    for feature in features_list:\n",
    "        if feature in review:\n",
    "            matched_features.add(feature)\n",
    "\n",
    "    # Fuzzy matching\n",
    "    if not matched_features:\n",
    "        words = review.split()\n",
    "        for word in words:\n",
    "            match, score, _ = process.extractOne(word, features_list, scorer=fuzz.partial_ratio)\n",
    "            if score >= threshold:\n",
    "                matched_features.add(match)\n",
    "\n",
    "    return list(matched_features)\n",
    "\n",
    "\n",
    "output_rows = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63891e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Feature   Car Company  \\\n",
      "0  ventilated seats  City   Honda   \n",
      "1              adas  City   Honda   \n",
      "2                ac  City   Honda   \n",
      "3                ac  City   Honda   \n",
      "4           gearbox  City   Honda   \n",
      "\n",
      "                                              Review  \n",
      "0  Great Family Car\\nGood car for day-to-day usag...  \n",
      "1  LKAS & RDMS\\nI have purchased honda amaze top ...  \n",
      "2  Sure Fo Good Deal.\\nVery good preference car i...  \n",
      "3  Best Quality Driving Experience Top Level Comf...  \n",
      "4  Best Quality Driving Experience Top Level Comf...  \n",
      "\n",
      "Total matched rows: 3601\n"
     ]
    }
   ],
   "source": [
    "for index, row in reviews_df.iterrows():\n",
    "    review_text = row[\"Cleaned_Review\"]\n",
    "    car = row[\"Car\"]\n",
    "    company = row[\"Company\"]\n",
    "    \n",
    "    matched = match_features_in_review(review_text)\n",
    "    \n",
    "    for feature in matched:\n",
    "        output_rows.append({\n",
    "            \"Feature\": feature,\n",
    "            \"Car\": car,\n",
    "            \"Company\": company,\n",
    "            \"Review\": row[\"Review\"]  \n",
    "        })\n",
    "\n",
    "matched_df = pd.DataFrame(output_rows)\n",
    "\n",
    "print(matched_df.head())\n",
    "print(f\"\\nTotal matched rows: {len(matched_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec95a2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RoBERTa sentiment model\n",
    "MODEL = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "labels = ['negative', 'neutral', 'positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fa0886",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_roberta(text):\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)  \n",
    "    text = emoji.demojize(text)          \n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1524ec5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_sentiment_score(text):\n",
    "    text = preprocess_roberta(text)\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    probs = torch.nn.functional.softmax(logits, dim=1).numpy()[0]\n",
    "    score = round(probs[2] * 1 + probs[1] * 0 + probs[0] * -1, 4)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b384ae42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_label(text):\n",
    "    text = preprocess_roberta(text)\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    probs = torch.nn.functional.softmax(logits, dim=1).numpy()[0]\n",
    "    return labels[np.argmax(probs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce5331c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_feature_context(review, feature):\n",
    "    sentences = sent_tokenize(review)\n",
    "    feature = feature.lower()\n",
    "    for sentence in sentences:\n",
    "        if feature in sentence.lower():\n",
    "            return f\"In my experience, {sentence}\"\n",
    "    return f\"In my experience, {review}\"  \n",
    "\n",
    "matched_df[\"Context\"] = matched_df.apply(lambda row: extract_feature_context(row[\"Review\"], row[\"Feature\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf221ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def assign_category(score):\n",
    "    if score >= 0.96:\n",
    "        return \"Highly Rated\"\n",
    "    elif score >= 0.90:\n",
    "        return \"Quality Rated\"\n",
    "    elif score < 0.4:\n",
    "        return \"Needs Improvement\"\n",
    "    else:\n",
    "        return \"Medium Rated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8002a4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "matched_df[\"Sentiment_Score\"] = matched_df[\"Context\"].apply(get_sentiment_score)\n",
    "matched_df[\"Sentiment_Label\"] = matched_df[\"Context\"].apply(get_sentiment_label)\n",
    "matched_df[\"Category\"] = matched_df[\"Sentiment_Score\"].apply(assign_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55b185c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_df = matched_df[[\"Feature\", \"Sentiment_Score\", \"Car\", \"Company\", \"Category\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96ad9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_df.to_excel(\"mid_size_sedan_output.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
